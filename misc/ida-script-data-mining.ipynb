{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "def create_folder(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def dump(path, data):\n",
    "    with open(path+'.pickle', 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=2)\n",
    "\n",
    "def dump_dict(d, base_path, depth, current_depth = 1, base_progress = \"\"):\n",
    "    create_folder(base_path)\n",
    "    i = 0\n",
    "    futures = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=1000) as executor:\n",
    "        for key in d:\n",
    "            progress = base_progress + f\"({i} / {len(d)-1})\"\n",
    "            path = os.path.join(base_path, str(key))\n",
    "            if isinstance(d[key], dict) and current_depth < depth:\n",
    "                print(progress)\n",
    "                dump_dict(d[key], path, depth, current_depth+1, progress + \" - \")\n",
    "            else:\n",
    "                futures.append(executor.submit(dump, path, d[key]))\n",
    "            i+=1\n",
    "        concurrent.futures.wait(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def buildOffsets(path):\n",
    "    df = pd.read_csv(path, sep='\\t', header=None)\n",
    "    df.head()\n",
    "    df[0] = df[0].apply(lambda x: str(int(x)))\n",
    "    df[1] = df[1].apply(lambda x: (x.lower()))\n",
    "    return {\n",
    "        \"skyrim-to-address\": dict(zip(df[1], df[0])),\n",
    "        \"address-to-skyrim\": dict(zip(df[0], df[1])),\n",
    "    }\n",
    "\n",
    "offsets318 = buildOffsets(\"offsets-1-6-318-0.txt\")\n",
    "offsets97 = buildOffsets(\"offsets-se-1.5.97.0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json \n",
    "\n",
    "\n",
    "df2 = pd.read_csv(\"known-addresses.txt\", sep=';', header=None)\n",
    "\n",
    "result_obj = {}\n",
    "\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    result_obj[row[1]] = {\n",
    "        \"name\":row[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pickle\n",
    "with open('input.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "pattern = r\"(NameAddr|TypeAddr)\\s*\\(\\s*([^,]+)\\s*,\\s*\\\"(.*)\\\"\\s*\\)\\s*\"\n",
    "\n",
    "for match in re.finditer(pattern, text):\n",
    "    if(match.group(1)):\n",
    "        key = offsets97[\"skyrim-to-address\"][match.group(2)[4:].lstrip(\"0\").lower()]\n",
    "        if(key not in result_obj):\n",
    "            result_obj[key] = {}\n",
    "        if(match.group(1) == \"NameAddr\"):\n",
    "            result_obj[key][\"name\"] = re.sub(r\"_14[^_]+$\", \"\", match.group(3))\n",
    "        else:\n",
    "            result_obj[key][\"definition\"] = match.group(3)\n",
    "\n",
    "\n",
    "dump_dict(result_obj,\"..\\\\data\\\\definition\\\\\",1)\n",
    "\n",
    "# with open(\"..\\\\data\\\\definition.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(result_obj, f, protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259868\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open('outputsorted.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "pattern = r\"^.*?14([a-zA-Z0-9]+)\\s+14([a-zA-Z0-9]+)\"\n",
    "\n",
    "result_obj = {\"ae\":{},\"se\":{}}\n",
    "\n",
    "\n",
    "\n",
    "for match in re.finditer(pattern, text, re.MULTILINE):\n",
    "    if(match.group(1)):\n",
    "        seid = match.group(1).lstrip('0').lower()\n",
    "        aeid = match.group(2).lstrip('0').lower()\n",
    "\n",
    "        if(aeid in offsets318[\"skyrim-to-address\"] and seid in offsets97[\"skyrim-to-address\"]):\n",
    "            ae = offsets318[\"skyrim-to-address\"][aeid]\n",
    "            se = offsets97[\"skyrim-to-address\"][seid]\n",
    "            result_obj[\"ae\"][ae] = se\n",
    "            result_obj[\"se\"][se] = ae\n",
    "\n",
    "print(len(result_obj[\"se\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259918\n",
      "(0 / 1)\n",
      "(1 / 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import json \n",
    "import pickle\n",
    "\n",
    "df2 = pd.read_csv(\"known-addresses.txt\", sep=';', header=None)\n",
    "\n",
    "for index, row in df2.iterrows():\n",
    "    result_obj[\"ae\"][str(row[2])] = str(row[1])\n",
    "    result_obj[\"se\"][str(row[1])] = str(row[2])\n",
    "\n",
    "print(len(result_obj[\"se\"].keys()))\n",
    "\n",
    "dump_dict(result_obj,\"..\\\\data\\\\addresses_match\\\\\",2)\n",
    "\n",
    "# with open(\"..\\\\data\\\\addresses_match.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(json.dumps(result_obj), f, protocol=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
